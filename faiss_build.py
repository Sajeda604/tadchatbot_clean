import os
import sys

from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader, PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEndpointEmbeddings


BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")
DB_FAISS_PATH = os.path.join(BASE_DIR, "vectorstore", "db_faiss")


def build_faiss_index() -> None:
    """Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© FAISS Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù…Ø¬Ù„Ø¯ data/ (.txt Ùˆ .pdf)."""

    load_dotenv()
    hf_token = os.getenv("HF_TOKEN")

    if not hf_token:
        raise RuntimeError("HF_TOKEN ØºÙŠØ± Ù…Ø¶Ø¨ÙˆØ· ÙÙŠ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©. Ù‚Ù… Ø¨Ø¶Ø¨Ø·Ù‡ Ù‚Ø¨Ù„ Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© FAISS.")

    if not os.path.isdir(DATA_DIR):
        raise FileNotFoundError(f"Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {DATA_DIR}")

    docs = []

    # ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª Ø§Ù„Ù†ØµÙˆØµ Ùˆ PDF
    for filename in sorted(os.listdir(DATA_DIR)):
        if not filename.lower().endswith((".txt", ".pdf")):
            continue

        file_path = os.path.join(DATA_DIR, filename)
        print(f"ğŸ“„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {filename}")

        try:
            if filename.lower().endswith(".txt"):
                loader = TextLoader(file_path, encoding="utf-8")
            else:
                loader = PyPDFLoader(file_path)

            docs.extend(loader.load())
        except Exception as e:  # pragma: no cover - ÙÙ‚Ø· Ù„Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„ØªØ´Ø®ÙŠØµÙŠØ©
            print(f"âš ï¸ ØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù {filename}: {e}")

    if not docs:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ø³ØªÙ†Ø¯Ø§Øª ØµØ§Ù„Ø­Ø© ÙÙŠ Ù…Ø¬Ù„Ø¯ data/.")
        return

    print("âœ‚ï¸ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø¥Ù„Ù‰ Ù…Ù‚Ø§Ø·Ø¹...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=150,
    )
    texts = text_splitter.split_documents(docs)

    print("ğŸ§  Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… HuggingFaceEndpointEmbeddings...")
    embeddings = HuggingFaceEndpointEmbeddings(
        model="sentence-transformers/all-MiniLM-L6-v2",
        task="feature-extraction",
        huggingfacehub_api_token=hf_token,
    )

    print("âš™ï¸ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª FAISS...")
    db = FAISS.from_documents(texts, embeddings)

    os.makedirs(DB_FAISS_PATH, exist_ok=True)
    db.save_local(DB_FAISS_PATH)
    print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª FAISS ÙˆØ­ÙØ¸Ù‡Ø§ ÙÙŠ: {DB_FAISS_PATH}")


def main() -> None:
    try:
        build_faiss_index()
    except Exception as exc:  # pragma: no cover - Ø³Ù„ÙˆÙƒ ØªÙØ§Ø¹Ù„ÙŠ ÙÙ‚Ø·
        print(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© FAISS: {exc}")
        sys.exit(1)


if __name__ == "__main__":
    main()
